# DeepLearning2
Deep Learning Course 2 Projects

Week 1 :
Implemented Regularization Techniques like DropOut,
Initialization of Parameters using Xavier Initialization,
Gradient Checking to Validate gradient descent, all from Scratch 

Week 2 :
Implemented Optimization Algorithms from Scratch :
Mini Batch Gradient Descent with Momentum
Adam
RMSprop
Learning Rate Decay

Week 3 :
Batch Normalization
HyperParameter tuning
Softmax regression
Built a Deep Neural Network in Tensorflow

